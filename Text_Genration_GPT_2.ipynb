{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UTEkT-mZOpVA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.inputs = []\n",
        "\n",
        "        for text in texts:\n",
        "            encoding = tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                max_length=max_length,\n",
        "                padding=\"max_length\",\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            self.inputs.append(encoding['input_ids'].squeeze())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"input_ids\": self.inputs[idx], \"labels\": self.inputs[idx]}\n",
        "\n",
        "def fine_tune_gpt2():\n",
        "    custom_texts = [\n",
        "        \"Artificial intelligence is transforming the world in unprecedented ways. Machine learning algorithms can now process vast amounts of data.\",\n",
        "        \"Natural language processing has made significant advances in recent years. Text generation models can create coherent and contextually relevant content.\",\n",
        "        \"Deep learning neural networks are capable of learning complex patterns from data. These models excel at tasks like image recognition and language understanding.\",\n",
        "        \"The future of AI holds immense potential for solving complex problems. From healthcare to climate change, AI applications are expanding rapidly.\",\n",
        "        \"Computer vision systems can now identify objects with human-level accuracy. This technology powers autonomous vehicles and medical imaging systems.\",\n",
        "        \"Reinforcement learning enables agents to learn optimal strategies through trial and error. This approach has achieved superhuman performance in games.\",\n",
        "        \"Transformer architectures have revolutionized natural language processing. Models like GPT and BERT have set new benchmarks in language tasks.\",\n",
        "        \"Data science combines statistics, programming, and domain expertise. It enables organizations to extract insights from large datasets.\",\n",
        "        \"Cloud computing provides scalable infrastructure for AI applications. This democratizes access to powerful computational resources.\",\n",
        "        \"Ethical AI development is crucial for responsible technology deployment. Bias mitigation and fairness are key considerations in model design.\"\n",
        "    ]\n",
        "\n",
        "    model_name = \"gpt2\"\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    dataset = CustomTextDataset(custom_texts, tokenizer)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False,\n",
        "    )\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./gpt2-finetuned\",\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=2,\n",
        "        per_device_eval_batch_size=2,\n",
        "        warmup_steps=10,\n",
        "        logging_steps=10,\n",
        "        save_steps=50,\n",
        "        eval_strategy=\"no\",\n",
        "        learning_rate=5e-5,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=\"./logs\",\n",
        "        dataloader_drop_last=False,\n",
        "        remove_unused_columns=False,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=dataset,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    print(\"Starting fine-tuning...\")\n",
        "    trainer.train()\n",
        "\n",
        "    print(\"Fine-tuning complete.\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def generate_text_from_prompt(model, tokenizer, prompt):\n",
        "    print(\"Generating sample text...\")\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs['input_ids'].to(model.device)\n",
        "    attention_mask = inputs['attention_mask'].to(model.device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=100,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"\\nGenerated text:\\n{generated_text}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, tokenizer = fine_tune_gpt2()\n",
        "\n",
        "    user_prompt = input(\"Enter your prompt for text generation: \")\n",
        "    generate_text_from_prompt(model, tokenizer, user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "C_ytiMlBPNhM",
        "outputId": "e65473b6-852f-463c-9aa3-a84ddabd461e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-3962492987.py:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.884000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning complete.\n",
            "Enter your prompt for text generation: medical \n",
            "Generating sample text...\n",
            "\n",
            "Generated text:\n",
            "medical ills have become more common in America. Research shows that people with these conditions are more likely than non-Hispanic whites to smoke and to consume alcohol.\n",
            "\n",
            "According to the US Centers for Disease Control and Prevention, nearly 1 in 5 deaths from cardiovascular disease are from smoking. Since the 1990s, there has been a rise in the number of people who smoke. This is partly caused by increased use of tobacco products.\n",
            "\n",
            "In the United States, more than half of all deaths that\n"
          ]
        }
      ]
    }
  ]
}